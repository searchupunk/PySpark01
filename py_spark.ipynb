{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes</br>\n",
    "pip install findspark\n",
    "pip install pyspark\n",
    "In this case need a virtual enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/02 11:25:28 WARN Utils: Your hostname, Nautas-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.26 instead (on interface en0)\n",
      "22/12/02 11:25:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/02 11:25:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.26:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Study</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb8216feb20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Study').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a DF using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+-------+---+------+------+------+------+-------+\n",
      "|   _c0|   _c1|_c2|    _c3|    _c4|    _c5|_c6|   _c7|   _c8|   _c9|  _c10|   _c11|\n",
      "+------+------+---+-------+-------+-------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address| income| ed|employ|retire|gender|reside|custcat|\n",
      "|     2|    13| 44|      1|      9| 64.000|  4|     5| 0.000|     0|     2|      1|\n",
      "|     3|    11| 33|      1|      7|136.000|  5|     5| 0.000|     0|     6|      4|\n",
      "|     3|    68| 52|      1|     24|116.000|  1|    29| 0.000|     1|     2|      3|\n",
      "|     2|    33| 33|      0|     12| 33.000|  2|     0| 0.000|     1|     1|      1|\n",
      "|     2|    23| 30|      1|      9| 30.000|  1|     2| 0.000|     0|     4|      3|\n",
      "|     2|    41| 39|      0|     17| 78.000|  2|    16| 0.000|     1|     1|      3|\n",
      "|     3|    45| 22|      1|      2| 19.000|  2|     4| 0.000|     1|     5|      2|\n",
      "|     2|    38| 35|      0|      5| 76.000|  2|    10| 0.000|     0|     3|      4|\n",
      "|     3|    45| 59|      1|      7|166.000|  4|    31| 0.000|     0|     5|      3|\n",
      "|     1|    68| 41|      1|     21| 72.000|  1|    22| 0.000|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10|125.000|  4|     5| 0.000|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14| 80.000|  2|    15| 0.000|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8| 37.000|  2|     9| 0.000|     1|     3|      1|\n",
      "|     2|    57| 54|      1|     30|115.000|  4|    23| 0.000|     1|     3|      4|\n",
      "|     2|     9| 46|      0|      3| 25.000|  1|     8| 0.000|     1|     2|      1|\n",
      "|     1|    29| 38|      1|     12| 75.000|  5|     1| 0.000|     0|     4|      2|\n",
      "|     3|    60| 57|      0|     38|162.000|  2|    30| 0.000|     0|     1|      3|\n",
      "|     3|    34| 48|      0|      3| 49.000|  2|     6| 0.000|     1|     3|      3|\n",
      "|     2|     1| 24|      0|      3| 20.000|  1|     3| 0.000|     0|     1|      1|\n",
      "+------+------+---+-------+-------+-------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv('teleCust1000t.csv')\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To keep the first name as a name for a columns we use read.option('header', 'true') </br>\n",
    "### Now for we keep the true type from de value data we need use inferSchema=True in csv() properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_columns = spark.read.option('header', 'true').csv('teleCust1000t.csv', inferSchema=True)\n",
    "df_spark_columns.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For info like .info()-Pandas We use .printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- region: integer (nullable = true)\n",
      " |-- tenure: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- marital: integer (nullable = true)\n",
      " |-- address: integer (nullable = true)\n",
      " |-- income: double (nullable = true)\n",
      " |-- ed: integer (nullable = true)\n",
      " |-- employ: integer (nullable = true)\n",
      " |-- retire: double (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- reside: integer (nullable = true)\n",
      " |-- custcat: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_columns.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to create the DF or a short way to create a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv('teleCust1000t.csv', header=True, inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- region: integer (nullable = true)\n",
      " |-- tenure: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- marital: integer (nullable = true)\n",
      " |-- address: integer (nullable = true)\n",
      " |-- income: double (nullable = true)\n",
      " |-- ed: integer (nullable = true)\n",
      " |-- employ: integer (nullable = true)\n",
      " |-- retire: double (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- reside: integer (nullable = true)\n",
      " |-- custcat: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region',\n",
       " 'tenure',\n",
       " 'age',\n",
       " 'marital',\n",
       " 'address',\n",
       " 'income',\n",
       " 'ed',\n",
       " 'employ',\n",
       " 'retire',\n",
       " 'gender',\n",
       " 'reside',\n",
       " 'custcat']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(region=2, tenure=13, age=44, marital=1, address=9, income=64.0, ed=4, employ=5, retire=0.0, gender=0, reside=2, custcat=1),\n",
       " Row(region=3, tenure=11, age=33, marital=1, address=7, income=136.0, ed=5, employ=5, retire=0.0, gender=0, reside=6, custcat=4),\n",
       " Row(region=3, tenure=68, age=52, marital=1, address=24, income=116.0, ed=1, employ=29, retire=0.0, gender=1, reside=2, custcat=3),\n",
       " Row(region=2, tenure=33, age=33, marital=0, address=12, income=33.0, ed=2, employ=0, retire=0.0, gender=1, reside=1, custcat=1),\n",
       " Row(region=2, tenure=23, age=30, marital=1, address=9, income=30.0, ed=1, employ=2, retire=0.0, gender=0, reside=4, custcat=3)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to pickup a column or a row or cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|region|\n",
      "+------+\n",
      "|     2|\n",
      "|     3|\n",
      "|     3|\n",
      "|     2|\n",
      "|     2|\n",
      "|     2|\n",
      "|     3|\n",
      "|     2|\n",
      "|     3|\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "|     1|\n",
      "|     2|\n",
      "|     2|\n",
      "|     1|\n",
      "|     3|\n",
      "|     3|\n",
      "|     2|\n",
      "|     1|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('region').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more then one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|marital|employ|\n",
      "+-------+------+\n",
      "|      1|     5|\n",
      "|      1|     5|\n",
      "|      1|    29|\n",
      "|      0|     0|\n",
      "|      1|     2|\n",
      "|      0|    16|\n",
      "|      1|     4|\n",
      "|      0|    10|\n",
      "|      1|    31|\n",
      "|      1|    22|\n",
      "|      0|     5|\n",
      "|      0|    15|\n",
      "|      1|     9|\n",
      "|      1|    23|\n",
      "|      0|     8|\n",
      "|      1|     1|\n",
      "|      0|    30|\n",
      "|      0|     6|\n",
      "|      0|     3|\n",
      "|      1|     2|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(['marital', 'employ']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to check the type from all components of the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('region', 'int'),\n",
       " ('tenure', 'int'),\n",
       " ('age', 'int'),\n",
       " ('marital', 'int'),\n",
       " ('address', 'int'),\n",
       " ('income', 'double'),\n",
       " ('ed', 'int'),\n",
       " ('employ', 'int'),\n",
       " ('retire', 'double'),\n",
       " ('gender', 'int'),\n",
       " ('reside', 'int'),\n",
       " ('custcat', 'int')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the describe method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+------------------+----------------+---------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "|summary|           region|            tenure|               age|           marital|           address|          income|             ed|            employ|             retire|            gender|            reside|           custcat|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+----------------+---------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "|  count|             1000|              1000|              1000|              1000|              1000|            1000|           1000|              1000|               1000|              1000|              1000|              1000|\n",
      "|   mean|            2.022|            35.526|            41.684|             0.495|            11.551|          77.535|          2.671|            10.987|              0.047|             0.517|             2.331|             2.487|\n",
      "| stddev|0.816199842062091|21.359811927204905|12.558816340239561|0.5002251745216602|10.086681324406955|107.044164849039|1.2223965204684|10.082087059705419|0.21174474216810166|0.4999609594367953|1.4357926384058741|1.1203062465621105|\n",
      "|    min|                1|                 1|                18|                 0|                 0|             9.0|              1|                 0|                0.0|                 0|                 1|                 1|\n",
      "|    max|                3|                72|                77|                 1|                55|          1668.0|              5|                47|                1.0|                 1|                 8|                 4|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+----------------+---------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How add column usin spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+----------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|age+employ|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+----------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|        49|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|        38|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|        81|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|        33|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|        32|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|        55|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|        26|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|        45|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|        90|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|        63|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|        38|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|        50|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|        47|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|        77|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|        54|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|        39|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|        87|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|        54|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|        27|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|        31|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.withColumn('age+employ', df_spark['age'] + df_spark['employ']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+---------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|newColumn|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+---------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|       49|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|       38|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|       81|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|       33|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|       32|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|       55|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|       26|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|       45|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|       90|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|       63|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|       38|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|       50|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|       47|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|       77|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|       54|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|       39|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|       87|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|       54|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|       27|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|       31|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add = df_spark['age'] + df_spark['employ']\n",
    "df_spark_nc = df_spark.withColumn('newColumn', add)\n",
    "df_spark_nc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to drop columns in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_nc = df_spark_nc.drop('newColumn')\n",
    "df_spark_nc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+-------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address|Entrada| ed|employ|retire|gender|reside|custcat|\n",
      "+------+------+---+-------+-------+-------+---+------+------+------+------+-------+\n",
      "|     2|    13| 44|      1|      9|   64.0|  4|     5|   0.0|     0|     2|      1|\n",
      "|     3|    11| 33|      1|      7|  136.0|  5|     5|   0.0|     0|     6|      4|\n",
      "|     3|    68| 52|      1|     24|  116.0|  1|    29|   0.0|     1|     2|      3|\n",
      "|     2|    33| 33|      0|     12|   33.0|  2|     0|   0.0|     1|     1|      1|\n",
      "|     2|    23| 30|      1|      9|   30.0|  1|     2|   0.0|     0|     4|      3|\n",
      "|     2|    41| 39|      0|     17|   78.0|  2|    16|   0.0|     1|     1|      3|\n",
      "|     3|    45| 22|      1|      2|   19.0|  2|     4|   0.0|     1|     5|      2|\n",
      "|     2|    38| 35|      0|      5|   76.0|  2|    10|   0.0|     0|     3|      4|\n",
      "|     3|    45| 59|      1|      7|  166.0|  4|    31|   0.0|     0|     5|      3|\n",
      "|     1|    68| 41|      1|     21|   72.0|  1|    22|   0.0|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10|  125.0|  4|     5|   0.0|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14|   80.0|  2|    15|   0.0|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8|   37.0|  2|     9|   0.0|     1|     3|      1|\n",
      "|     2|    57| 54|      1|     30|  115.0|  4|    23|   0.0|     1|     3|      4|\n",
      "|     2|     9| 46|      0|      3|   25.0|  1|     8|   0.0|     1|     2|      1|\n",
      "|     1|    29| 38|      1|     12|   75.0|  5|     1|   0.0|     0|     4|      2|\n",
      "|     3|    60| 57|      0|     38|  162.0|  2|    30|   0.0|     0|     1|      3|\n",
      "|     3|    34| 48|      0|      3|   49.0|  2|     6|   0.0|     1|     3|      3|\n",
      "|     2|     1| 24|      0|      3|   20.0|  1|     3|   0.0|     0|     1|      1|\n",
      "|     1|    26| 29|      1|      3|   77.0|  4|     2|   0.0|     0|     4|      4|\n",
      "+------+------+---+-------+-------+-------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_nc.withColumnRenamed('income', 'Entrada').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "##How to drop fill and replace a NaN or Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.drop().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "using the df_spar.na.drop() we can use the propertie how= and especiffy what drop: </br>\n",
    "how='any' is defaul - this drop any how with null value </br>\n",
    "how='all' we use to drop all rows with all values null </br>\n",
    "how='any' with thresh=2 -- this combination going to delete all rows with more then 2 values nonull </br>\n",
    "We have another propertie subset= with subset= we can drop chosen a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.drop(how='any', subset='address').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "To fill a NaN or Null value we can use spark.na.fill()<br/>\n",
    "If we just put one paramiter such as 'FILL_Value'all null will became 'FILL_Value'<br>\n",
    "But if we want to fill just in a specific column we use the seconde paramiter with tha name of the column<br>\n",
    "such as spark.na.fill('FILL_Value', 'address') if we want to fill more than one column we use square brackets inside the parentheses such as spark.na.fill('FILL_Value', ['address', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.fill('FILL_value', 'address').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Here we use the Imputer to take al values an create a copy or put the mean value on the null spot<br>\n",
    "we calculate the mean or median or mode using .setStrategy() and in a propertie we put mean, median or mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer, VectorAssembler\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['region','tenure','age','marital','address',\n",
    "                'income','ed','employ','retire','gender','reside','custcat'],\n",
    "    outputCols=['{}_imputed'.format(c) for c in ['region','tenure','age','marital','address',\n",
    "                'income','ed','employ','retire','gender','reside','custcat']]            \n",
    "    ).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add imputation columns to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+--------------+--------------+-----------+---------------+---------------+--------------+----------+--------------+--------------+--------------+--------------+---------------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|region_imputed|tenure_imputed|age_imputed|marital_imputed|address_imputed|income_imputed|ed_imputed|employ_imputed|retire_imputed|gender_imputed|reside_imputed|custcat_imputed|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+--------------+--------------+-----------+---------------+---------------+--------------+----------+--------------+--------------+--------------+--------------+---------------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|             2|            13|         44|              1|              9|          64.0|         4|             5|           0.0|             0|             2|              1|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|             3|            11|         33|              1|              7|         136.0|         5|             5|           0.0|             0|             6|              4|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|             3|            68|         52|              1|             24|         116.0|         1|            29|           0.0|             1|             2|              3|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|             2|            33|         33|              0|             12|          33.0|         2|             0|           0.0|             1|             1|              1|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|             2|            23|         30|              1|              9|          30.0|         1|             2|           0.0|             0|             4|              3|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|             2|            41|         39|              0|             17|          78.0|         2|            16|           0.0|             1|             1|              3|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|             3|            45|         22|              1|              2|          19.0|         2|             4|           0.0|             1|             5|              2|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|             2|            38|         35|              0|              5|          76.0|         2|            10|           0.0|             0|             3|              4|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|             3|            45|         59|              1|              7|         166.0|         4|            31|           0.0|             0|             5|              3|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|             1|            68|         41|              1|             21|          72.0|         1|            22|           0.0|             0|             3|              2|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|             2|             5|         33|              0|             10|         125.0|         4|             5|           0.0|             1|             1|              1|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|             3|             7|         35|              0|             14|          80.0|         2|            15|           0.0|             1|             1|              3|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|             1|            41|         38|              1|              8|          37.0|         2|             9|           0.0|             1|             3|              1|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|             2|            57|         54|              1|             30|         115.0|         4|            23|           0.0|             1|             3|              4|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|             2|             9|         46|              0|              3|          25.0|         1|             8|           0.0|             1|             2|              1|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|             1|            29|         38|              1|             12|          75.0|         5|             1|           0.0|             0|             4|              2|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|             3|            60|         57|              0|             38|         162.0|         2|            30|           0.0|             0|             1|              3|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|             3|            34|         48|              0|              3|          49.0|         2|             6|           0.0|             1|             3|              3|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|             2|             1|         24|              0|              3|          20.0|         1|             3|           0.0|             0|             1|              1|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|             1|            26|         29|              1|              3|          77.0|         4|             2|           0.0|             0|             4|              4|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+--------------+--------------+-----------+---------------+---------------+--------------+----------+--------------+--------------+--------------+--------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_spark).transform(df_spark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## filter operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the comparation we need write into clotes because if we don't, they will show as an erros <br>\n",
    "such as cannot compare str with int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|\n",
      "|     3|     6| 30|      0|      7|  16.0|  3|     1|   0.0|     1|     1|      2|\n",
      "|     3|    53| 33|      0|     10| 101.0|  5|     4|   0.0|     1|     2|      4|\n",
      "|     3|    14| 43|      1|     18|  36.0|  1|     5|   0.0|     0|     5|      3|\n",
      "|     2|     1| 21|      0|      0|  33.0|  2|     0|   0.0|     1|     3|      3|\n",
      "|     2|    42| 40|      0|      7|  37.0|  2|     8|   0.0|     1|     1|      4|\n",
      "|     3|    25| 33|      1|     11|  31.0|  1|     5|   0.0|     0|     4|      3|\n",
      "|     1|     9| 21|      1|      1|  17.0|  2|     2|   0.0|     1|     3|      1|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_nc.filter('age < 44').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can be more specific using the .select() function like so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|employ|\n",
      "+------+\n",
      "|    29|\n",
      "|    31|\n",
      "|    23|\n",
      "|    30|\n",
      "|    24|\n",
      "|    12|\n",
      "|    25|\n",
      "|    17|\n",
      "|    35|\n",
      "|    19|\n",
      "|    12|\n",
      "|     0|\n",
      "|     2|\n",
      "|     2|\n",
      "|    23|\n",
      "|    10|\n",
      "|    34|\n",
      "|     9|\n",
      "|    12|\n",
      "|    47|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_nc.filter('age > 50').select('employ').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter in this way too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|\n",
      "|     3|    53| 33|      0|     10| 101.0|  5|     4|   0.0|     1|     2|      4|\n",
      "|     3|    14| 43|      1|     18|  36.0|  1|     5|   0.0|     0|     5|      3|\n",
      "|     2|    42| 40|      0|      7|  37.0|  2|     8|   0.0|     1|     1|      4|\n",
      "|     3|    25| 33|      1|     11|  31.0|  1|     5|   0.0|     0|     4|      3|\n",
      "|     2|    13| 33|      1|      9|  19.0|  4|     0|   0.0|     1|     2|      2|\n",
      "|     1|    56| 37|      1|      6|  36.0|  1|    13|   0.0|     1|     2|      2|\n",
      "|     2|    60| 46|      1|     13| 163.0|  3|    24|   0.0|     0|     2|      4|\n",
      "|     3|    20| 35|      1|     11|  52.0|  4|     0|   0.0|     0|     2|      2|\n",
      "|     1|    11| 41|      1|      0|  39.0|  1|     1|   0.0|     1|     2|      3|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_nc.filter((df_spark_nc['age'] < 48) & (df_spark_nc['age'] > 30)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## GroupBy and Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----------+--------+------------+------------+-----------+-------+-----------+-----------+-----------+-----------+------------+\n",
      "|income|sum(region)|sum(tenure)|sum(age)|sum(marital)|sum(address)|sum(income)|sum(ed)|sum(employ)|sum(retire)|sum(gender)|sum(reside)|sum(custcat)|\n",
      "+------+-----------+-----------+--------+------------+------------+-----------+-------+-----------+-----------+-----------+-----------+------------+\n",
      "| 170.0|          1|         71|      56|           0|          23|      170.0|      1|         30|        0.0|          1|          1|           4|\n",
      "| 147.0|          3|         72|     108|           0|          45|      294.0|      4|         60|        0.0|          1|          5|           5|\n",
      "| 169.0|          2|         45|      52|           1|           4|      169.0|      4|         29|        0.0|          1|          4|           2|\n",
      "| 608.0|          3|         65|      56|           1|          19|      608.0|      3|         34|        0.0|          1|          2|           4|\n",
      "|  67.0|         17|        398|     374|           5|         134|      536.0|     21|        138|        1.0|          5|         19|          14|\n",
      "|  70.0|          6|        171|     167|           2|          43|      280.0|     13|         40|        0.0|          2|          7|          13|\n",
      "| 311.0|          3|         59|      57|           0|          26|      311.0|      3|         36|        0.0|          1|          1|           1|\n",
      "| 168.0|          4|        133|     109|           1|          47|      336.0|      3|         69|        0.0|          2|          4|           7|\n",
      "|  69.0|          6|        154|     175|           1|          44|      276.0|     11|         32|        0.0|          2|          7|          11|\n",
      "| 142.0|          2|         84|      87|           1|          39|      284.0|      3|         48|        0.0|          1|          3|           3|\n",
      "| 191.0|          2|         63|      63|           1|          19|      191.0|      3|         27|        0.0|          0|          2|           2|\n",
      "|1131.0|          3|         70|      68|           0|          21|     1131.0|      2|         45|        0.0|          0|          1|           3|\n",
      "| 112.0|          5|        102|     164|           1|          34|      336.0|     12|         22|        0.0|          2|          6|           7|\n",
      "| 232.0|          2|         15|      46|           0|           5|      232.0|      4|         15|        0.0|          1|          2|           4|\n",
      "| 438.0|          2|         69|      51|           1|          11|      438.0|      4|         23|        0.0|          1|          2|           4|\n",
      "| 928.0|          1|         41|      52|           0|          26|      928.0|      3|         29|        0.0|          0|          3|           3|\n",
      "| 456.0|          3|         68|      52|           1|           8|      456.0|      3|         30|        0.0|          1|          4|           3|\n",
      "| 128.0|          4|         93|     113|           1|          47|      256.0|      7|         28|        0.0|          1|          3|           7|\n",
      "| 201.0|          2|         32|      44|           0|          10|      201.0|      2|         24|        0.0|          0|          1|           3|\n",
      "| 108.0|          6|        188|     197|           1|          64|      432.0|      9|         82|        0.0|          1|          9|          11|\n",
      "+------+-----------+-----------+--------+------------+------------+-----------+-------+-----------+-----------+-----------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy('income').sum().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Using .agg() isolated and as a propertie we can pass functions inside de brakets such a MEAN in a example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|  41.684|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.agg({'age' : 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureassembler = VectorAssembler(inputCols=['marital','employ'], outputCol='Independet features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = featureassembler.transform(df_spark_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+-------------------+\n",
      "|region|tenure|age|marital|address|income| ed|employ|retire|gender|reside|custcat|Independet features|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+-------------------+\n",
      "|     2|    13| 44|      1|      9|  64.0|  4|     5|   0.0|     0|     2|      1|          [1.0,5.0]|\n",
      "|     3|    11| 33|      1|      7| 136.0|  5|     5|   0.0|     0|     6|      4|          [1.0,5.0]|\n",
      "|     3|    68| 52|      1|     24| 116.0|  1|    29|   0.0|     1|     2|      3|         [1.0,29.0]|\n",
      "|     2|    33| 33|      0|     12|  33.0|  2|     0|   0.0|     1|     1|      1|          (2,[],[])|\n",
      "|     2|    23| 30|      1|      9|  30.0|  1|     2|   0.0|     0|     4|      3|          [1.0,2.0]|\n",
      "|     2|    41| 39|      0|     17|  78.0|  2|    16|   0.0|     1|     1|      3|         [0.0,16.0]|\n",
      "|     3|    45| 22|      1|      2|  19.0|  2|     4|   0.0|     1|     5|      2|          [1.0,4.0]|\n",
      "|     2|    38| 35|      0|      5|  76.0|  2|    10|   0.0|     0|     3|      4|         [0.0,10.0]|\n",
      "|     3|    45| 59|      1|      7| 166.0|  4|    31|   0.0|     0|     5|      3|         [1.0,31.0]|\n",
      "|     1|    68| 41|      1|     21|  72.0|  1|    22|   0.0|     0|     3|      2|         [1.0,22.0]|\n",
      "|     2|     5| 33|      0|     10| 125.0|  4|     5|   0.0|     1|     1|      1|          [0.0,5.0]|\n",
      "|     3|     7| 35|      0|     14|  80.0|  2|    15|   0.0|     1|     1|      3|         [0.0,15.0]|\n",
      "|     1|    41| 38|      1|      8|  37.0|  2|     9|   0.0|     1|     3|      1|          [1.0,9.0]|\n",
      "|     2|    57| 54|      1|     30| 115.0|  4|    23|   0.0|     1|     3|      4|         [1.0,23.0]|\n",
      "|     2|     9| 46|      0|      3|  25.0|  1|     8|   0.0|     1|     2|      1|          [0.0,8.0]|\n",
      "|     1|    29| 38|      1|     12|  75.0|  5|     1|   0.0|     0|     4|      2|          [1.0,1.0]|\n",
      "|     3|    60| 57|      0|     38| 162.0|  2|    30|   0.0|     0|     1|      3|         [0.0,30.0]|\n",
      "|     3|    34| 48|      0|      3|  49.0|  2|     6|   0.0|     1|     3|      3|          [0.0,6.0]|\n",
      "|     2|     1| 24|      0|      3|  20.0|  1|     3|   0.0|     0|     1|      1|          [0.0,3.0]|\n",
      "|     1|    26| 29|      1|      3|  77.0|  4|     2|   0.0|     0|     4|      4|          [1.0,2.0]|\n",
      "+------+------+---+-------+-------+------+---+------+------+------+------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|Independet features|income|\n",
      "+-------------------+------+\n",
      "|          [1.0,5.0]|  64.0|\n",
      "|          [1.0,5.0]| 136.0|\n",
      "|         [1.0,29.0]| 116.0|\n",
      "|          (2,[],[])|  33.0|\n",
      "|          [1.0,2.0]|  30.0|\n",
      "|         [0.0,16.0]|  78.0|\n",
      "|          [1.0,4.0]|  19.0|\n",
      "|         [0.0,10.0]|  76.0|\n",
      "|         [1.0,31.0]| 166.0|\n",
      "|         [1.0,22.0]|  72.0|\n",
      "|          [0.0,5.0]| 125.0|\n",
      "|         [0.0,15.0]|  80.0|\n",
      "|          [1.0,9.0]|  37.0|\n",
      "|         [1.0,23.0]| 115.0|\n",
      "|          [0.0,8.0]|  25.0|\n",
      "|          [1.0,1.0]|  75.0|\n",
      "|         [0.0,30.0]| 162.0|\n",
      "|          [0.0,6.0]|  49.0|\n",
      "|          [0.0,3.0]|  20.0|\n",
      "|          [1.0,2.0]|  77.0|\n",
      "+-------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data = output.select('Independet features', 'income')\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = finalized_data.randomSplit([0.75, 0.25])\n",
    "regressor = LinearRegression(featuresCol= 'Independet features', labelCol='income')\n",
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-1.4038, 5.1536])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.453491896073047"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------------------+\n",
      "|Independet features|income|        prediction|\n",
      "+-------------------+------+------------------+\n",
      "|          (2,[],[])|  15.0|20.453491896073047|\n",
      "|          (2,[],[])|  16.0|20.453491896073047|\n",
      "|          (2,[],[])|  19.0|20.453491896073047|\n",
      "|          (2,[],[])|  22.0|20.453491896073047|\n",
      "|          (2,[],[])|  25.0|20.453491896073047|\n",
      "|          (2,[],[])|  33.0|20.453491896073047|\n",
      "|          (2,[],[])|  37.0|20.453491896073047|\n",
      "|          (2,[],[])|  41.0|20.453491896073047|\n",
      "|          (2,[],[])|  46.0|20.453491896073047|\n",
      "|          (2,[],[])|  65.0|20.453491896073047|\n",
      "|          [0.0,1.0]|  21.0|25.607120616856793|\n",
      "|          [0.0,1.0]|  38.0|25.607120616856793|\n",
      "|          [0.0,1.0]|  57.0|25.607120616856793|\n",
      "|          [0.0,2.0]|  17.0| 30.76074933764054|\n",
      "|          [0.0,2.0]|  30.0| 30.76074933764054|\n",
      "|          [0.0,2.0]|  34.0| 30.76074933764054|\n",
      "|          [0.0,2.0]|  42.0| 30.76074933764054|\n",
      "|          [0.0,2.0]|  69.0| 30.76074933764054|\n",
      "|          [0.0,3.0]|  20.0| 35.91437805842429|\n",
      "|          [0.0,3.0]|  20.0| 35.91437805842429|\n",
      "+-------------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42.494840882447676, 13951.541339429821)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/02 14:56:38 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 203307 ms exceeds timeout 120000 ms\n",
      "22/12/02 14:56:38 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError, pred_results.meanSquaredError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
